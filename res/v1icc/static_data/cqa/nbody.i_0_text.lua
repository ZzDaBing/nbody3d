_cqa_text_report = {
  paths = {
    {
      hint = {
        {
          workaround = " - Pass to your compiler a micro-architecture specialization option:\n  * Please read your compiler manual\n - Use vector aligned instructions:\n  1) align your arrays on 64 bytes boundaries\n  2) inform your compiler that your arrays are vector aligned: read your compiler manual.\n",
          details = " - VEXTRACTF64X4: 6 occurrences\n",
          title = "Vector unaligned load/store instructions",
          txt = "Detected 6 suboptimal vector unaligned load/store instructions.\n",
        },
        {
          title = "Type of elements and instruction set",
          txt = "6 SSE or AVX instructions are processing arithmetic or math operations on single precision FP elements in scalar mode (one at a time).\n24 AVX instructions are processing arithmetic or math operations on single precision FP elements in vector mode (eight at a time).\n",
        },
        {
          title = "Matching between your loop (in the source code) and the binary loop",
          txt = "The binary loop is composed of 198 FP arithmetical operations:\n - 198: addition or subtraction\nThe binary loop is loading 192 bytes (48 single precision FP elements).\nThe binary loop is storing 48 bytes (12 single precision FP elements).",
        },
        {
          title = "Arithmetic intensity",
          txt = "Arithmetic intensity is 0.82 FP operations per loaded or stored byte.",
        },
      },
      expert = {
        {
          title = "General properties",
          txt = "nb instructions    : 118\nloop length        : 699\nused x86 registers : 10\nused mmx registers : 0\nused xmm registers : 14\nused ymm registers : 16\nused zmm registers : 20\nnb stack references: 14\n",
        },
        {
          title = "Front-end",
          txt = "MACRO FUSION NOT POSSIBLE\ninstruction fetch    : 44.00 cycles\ninstruction queue    : 59.00 cycles\ndecoding             : 59.00 cycles\nmicro-operation queue: 59.00 cycles\nfront end            : 59.00 cycles\n",
        },
        {
          title = "Back-end",
          txt = "       | P0    | P1    | P2    | P3    | P4   | P5   | P6\n------------------------------------------------------------\nuops   | 41.50 | 41.50 | 14.00 | 14.00 | 8.00 | 8.00 | 12.00\ncycles | 41.50 | 41.50 | 14.00 | 14.00 | 8.00 | 8.00 | 12.00\n\nCycles executing div or sqrt instructions: NA\n",
        },
        {
          title = "Cycles summary",
          txt = "Front-end : 59.00\nDispatch  : 41.50\nOverall L1: 59.00\n",
        },
        {
          title = "Vectorization ratios",
          txt = "INT\nall    : 50%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 50%\nFP\nall     : 59%\nload    : 14%\nstore   : 0%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 80%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 59%\nINT+FP\nall     : 58%\nload    : 14%\nstore   : 0%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 80%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 57%\n",
        },
        {
          title = "Vector efficiency ratios",
          txt = "INT\nall    : 17%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 17%\nFP\nall     : 34%\nload    : 19%\nstore   : 6%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 41%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 34%\nINT+FP\nall     : 32%\nload    : 19%\nstore   : 6%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 41%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 30%\n",
        },
        {
          title = "Cycles and memory resources usage",
          txt = "Detected masked instructions: assuming all mask elements are active.\nAssuming all data fit into the L1 cache, each iteration of the binary loop takes 59.00 cycles. At this rate:\n - 2% of peak load performance is reached (3.25 out of 128.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 1% of peak store performance is reached (0.81 out of 64.00 bytes stored per cycle (GB/s @ 1GHz))\n",
        },
        {
          title = "Front-end bottlenecks",
          txt = "Performance is limited by instruction throughput (loading/decoding program instructions to execution core) (front-end is a bottleneck).\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 59.00 to 44.00 cycles (1.34x speedup).\n",
        },
        {
          title = "ASM code",
          txt = "In the binary file, the address of the loop is: 4047e7\n\nInstruction                            | Nb FU | P0   | P1   | P2   | P3   | P4   | P5   | P6 | Latency | Recip. throughput\n---------------------------------------------------------------------------------------------------------------------------\nJMP 404423 <main+0x2133>               | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 2\nMOV 0x98(%RSP),%R11                    | 1     | 0    | 0    | 1    | 0    | 0    | 0    | 0  | 4       | 1\nVMOVSS %XMM5,0xe8(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nMOV $0x1,%ECX                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM0,0xec(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nKMOVW %ECX,%K1                         | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 5       | 1\nVMOVSS %XMM1,0xf0(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nLEA 0x10(%R8),%RCX                     | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM2,0xf4(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVBROADCASTSS 0xe8(%RSP),%ZMM9{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVMOVSS %XMM3,0xf8(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVBROADCASTSS 0xec(%RSP),%ZMM10{%K1}{z} | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVMOVSS %XMM4,0xfc(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVBROADCASTSS 0xf0(%RSP),%ZMM6{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xf4(%RSP),%ZMM11{%K1}{z} | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xf8(%RSP),%ZMM7{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xfc(%RSP),%ZMM8{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nCMP %RCX,%R11                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nJB 4047e7 <main+0x24f7>                | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 1-2\nLEA 0x1(%R11),%RCX                     | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nCMP %R14,%RCX                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nJA 404bfb <main+0x290b>                | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 1-2\nVMOVSS %XMM5,0xc0(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nMOV $0x1,%ECX                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM0,0xc4(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nMOV %R14,%R8                           | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 0       | 0.50\nVMOVSS %XMM1,0xc8(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nKMOVW %ECX,%K1                         | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 5       | 1\nVMOVSS %XMM2,0xcc(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nSUB %R11,%R8                           | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM3,0xd0(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVMOVAPS %ZMM16,%ZMM27                  | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 2       | 0.50\nVMOVSS %XMM4,0xd4(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVMOVAPS %ZMM17,%ZMM26                  | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 2       | 0.50\nXOR %ECX,%ECX\nVBROADCASTSS 0xc0(%RSP),%ZMM7{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xc4(%RSP),%ZMM6{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xc8(%RSP),%ZMM5{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xcc(%RSP),%ZMM2{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xd0(%RSP),%ZMM1{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xd4(%RSP),%ZMM0{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS %XMM18,%ZMM25             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM15,%ZMM24             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM14,%ZMM23             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM13,%ZMM22             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM21,%ZMM18             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM20,%ZMM9              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVPBROADCASTQ %R8,%ZMM11                | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3       | 1\nLEA (%R13,%R11,4),%R9                  | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nLEA (%RDX,%R11,4),%R10                 | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nLEA (%R12,%R11,4),%R11                 | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVUPS 0xf808(%RIP),%ZMM10            | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVMOVUPS 0xf77e(%RIP),%ZMM12            | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVEXTRACTF64X4 $0x1,%ZMM1,%YMM15        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM1,%YMM15,%YMM1              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVEXTRACTF64X4 $0x1,%ZMM0,%YMM4         | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM0,%YMM4,%YMM8               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x56,%YMM1,%YMM0             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x1,%YMM8,%YMM3              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM8,%YMM9             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM8,%YMM10             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM8,%YMM3,%YMM11              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM12             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM1,%YMM3              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM12,%YMM11,%YMM13            | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $0x55,%YMM1,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM1,%YMM3,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM13,%XMM14             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM13,%XMM14,%XMM4             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVEXTRACTF64X4 $0x1,%ZMM2,%YMM13        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM8,%YMM0,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM2,%YMM13,%YMM1              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM1,%YMM2              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM1,%YMM0             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM1,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVEXTRACTF64X4 $0x1,%ZMM5,%YMM14        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM1,%YMM2,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM0,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM5,%YMM14,%YMM0              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM3             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM0,%YMM1              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM0,%YMM5             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM0,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVEXTRACTF64X4 $0x1,%ZMM6,%YMM13        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM0,%YMM1,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM5,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM6,%YMM13,%YMM5              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM2             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM5,%YMM0              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM5,%YMM6             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM5,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVEXTRACTF64X4 $0x1,%ZMM7,%YMM13        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM5,%YMM0,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM6,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM7,%YMM13,%YMM6              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM1             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM6,%YMM5              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM6,%YMM7             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM6,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM6,%YMM5,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM7,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM0             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM5             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nXOR %R11D,%R11D\nJMP 4047e7 <main+0x24f7>               | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 2\nMOV 0x40(%RSP),%R11                    | 1     | 0    | 0    | 1    | 0    | 0    | 0    | 0  | 4       | 1\nXOR %R8D,%R8D\nJMP 404423 <main+0x2133>               | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 2\n",
        },
      },
      header = {
        "5% of peak computational performance is used (3.36 out of 64.00 FLOP per cycle (GFLOPS @ 1GHz))",
      },
      brief = {
      },
      gain = {
        {
          workaround = " - Try to reorganize arrays of structures to structures of arrays\n - Consider to permute loops (see vectorization gain report)\n",
          title = "Code clean check",
          txt = "Detected a slowdown caused by scalar integer instructions (typically used for address computation).\nBy removing them, you can lower the cost of an iteration from 59.00 to 51.00 cycles (1.16x speedup).",
        },
        {
          workaround = " - Try another compiler or update/tune your current one\n - Remove inter-iterations dependences from your loop and make it unit-stride:\n  * If your arrays have 2 or more dimensions, check whether elements are accessed contiguously and, otherwise, try to permute loops accordingly\n  * If your loop streams arrays of structures (AoS), try to use structures of arrays instead (SoA)\n",
          details = "58% of SSE/AVX instructions are used in vector version (process two or more data elements in vector registers):\n - 14% of SSE/AVX loads are used in vector version.\n - 0% of SSE/AVX stores are used in vector version.\n - 80% of SSE/AVX addition or subtraction instructions are used in vector version.\n - 57% of SSE/AVX instructions that are not load, store, addition, subtraction nor multiply instructions are used in vector version.\nSince your execution units are vector units, only a fully vectorized loop can use their full power.\n",
          title = "Vectorization",
          txt = "Your loop is partially vectorized.\nOnly 32% of vector register length is used (average across all SSE/AVX instructions).\nBy fully vectorizing your loop, you can lower the cost of an iteration from 59.00 to 26.56 cycles (2.22x speedup).",
        },
        {
          title = "Execution units bottlenecks",
          txt = "Found no such bottlenecks but see expert reports for more complex bottlenecks.",
        },
      },
      potential = {
      },
    },
  },
  AVG = {
      hint = {
        {
          workaround = " - Pass to your compiler a micro-architecture specialization option:\n  * Please read your compiler manual\n - Use vector aligned instructions:\n  1) align your arrays on 64 bytes boundaries\n  2) inform your compiler that your arrays are vector aligned: read your compiler manual.\n",
          details = " - VEXTRACTF64X4: 6 occurrences\n",
          title = "Vector unaligned load/store instructions",
          txt = "Detected 6 suboptimal vector unaligned load/store instructions.\n",
        },
        {
          title = "Type of elements and instruction set",
          txt = "6 SSE or AVX instructions are processing arithmetic or math operations on single precision FP elements in scalar mode (one at a time).\n24 AVX instructions are processing arithmetic or math operations on single precision FP elements in vector mode (eight at a time).\n",
        },
        {
          title = "Matching between your loop (in the source code) and the binary loop",
          txt = "The binary loop is composed of 198 FP arithmetical operations:\n - 198: addition or subtraction\nThe binary loop is loading 192 bytes (48 single precision FP elements).\nThe binary loop is storing 48 bytes (12 single precision FP elements).",
        },
        {
          title = "Arithmetic intensity",
          txt = "Arithmetic intensity is 0.82 FP operations per loaded or stored byte.",
        },
      },
      expert = {
        {
          title = "General properties",
          txt = "nb instructions    : 118\nloop length        : 699\nused x86 registers : 10\nused mmx registers : 0\nused xmm registers : 14\nused ymm registers : 16\nused zmm registers : 20\nnb stack references: 14\n",
        },
        {
          title = "Front-end",
          txt = "MACRO FUSION NOT POSSIBLE\ninstruction fetch    : 44.00 cycles\ninstruction queue    : 59.00 cycles\ndecoding             : 59.00 cycles\nmicro-operation queue: 59.00 cycles\nfront end            : 59.00 cycles\n",
        },
        {
          title = "Back-end",
          txt = "       | P0    | P1    | P2    | P3    | P4   | P5   | P6\n------------------------------------------------------------\nuops   | 41.50 | 41.50 | 14.00 | 14.00 | 8.00 | 8.00 | 12.00\ncycles | 41.50 | 41.50 | 14.00 | 14.00 | 8.00 | 8.00 | 12.00\n\nCycles executing div or sqrt instructions: NA\n",
        },
        {
          title = "Cycles summary",
          txt = "Front-end : 59.00\nDispatch  : 41.50\nOverall L1: 59.00\n",
        },
        {
          title = "Vectorization ratios",
          txt = "INT\nall    : 50%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 50%\nFP\nall     : 59%\nload    : 14%\nstore   : 0%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 80%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 59%\nINT+FP\nall     : 58%\nload    : 14%\nstore   : 0%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 80%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 57%\n",
        },
        {
          title = "Vector efficiency ratios",
          txt = "INT\nall    : 17%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 17%\nFP\nall     : 34%\nload    : 19%\nstore   : 6%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 41%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 34%\nINT+FP\nall     : 32%\nload    : 19%\nstore   : 6%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 41%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : 30%\n",
        },
        {
          title = "Cycles and memory resources usage",
          txt = "Detected masked instructions: assuming all mask elements are active.\nAssuming all data fit into the L1 cache, each iteration of the binary loop takes 59.00 cycles. At this rate:\n - 2% of peak load performance is reached (3.25 out of 128.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 1% of peak store performance is reached (0.81 out of 64.00 bytes stored per cycle (GB/s @ 1GHz))\n",
        },
        {
          title = "Front-end bottlenecks",
          txt = "Performance is limited by instruction throughput (loading/decoding program instructions to execution core) (front-end is a bottleneck).\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 59.00 to 44.00 cycles (1.34x speedup).\n",
        },
        {
          title = "ASM code",
          txt = "In the binary file, the address of the loop is: 4047e7\n\nInstruction                            | Nb FU | P0   | P1   | P2   | P3   | P4   | P5   | P6 | Latency | Recip. throughput\n---------------------------------------------------------------------------------------------------------------------------\nJMP 404423 <main+0x2133>               | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 2\nMOV 0x98(%RSP),%R11                    | 1     | 0    | 0    | 1    | 0    | 0    | 0    | 0  | 4       | 1\nVMOVSS %XMM5,0xe8(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nMOV $0x1,%ECX                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM0,0xec(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nKMOVW %ECX,%K1                         | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 5       | 1\nVMOVSS %XMM1,0xf0(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nLEA 0x10(%R8),%RCX                     | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM2,0xf4(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVBROADCASTSS 0xe8(%RSP),%ZMM9{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVMOVSS %XMM3,0xf8(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVBROADCASTSS 0xec(%RSP),%ZMM10{%K1}{z} | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVMOVSS %XMM4,0xfc(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVBROADCASTSS 0xf0(%RSP),%ZMM6{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xf4(%RSP),%ZMM11{%K1}{z} | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xf8(%RSP),%ZMM7{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xfc(%RSP),%ZMM8{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nCMP %RCX,%R11                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nJB 4047e7 <main+0x24f7>                | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 1-2\nLEA 0x1(%R11),%RCX                     | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nCMP %R14,%RCX                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nJA 404bfb <main+0x290b>                | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 1-2\nVMOVSS %XMM5,0xc0(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nMOV $0x1,%ECX                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM0,0xc4(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nMOV %R14,%R8                           | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 0       | 0.50\nVMOVSS %XMM1,0xc8(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nKMOVW %ECX,%K1                         | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 5       | 1\nVMOVSS %XMM2,0xcc(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nSUB %R11,%R8                           | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVSS %XMM3,0xd0(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVMOVAPS %ZMM16,%ZMM27                  | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 2       | 0.50\nVMOVSS %XMM4,0xd4(%RSP)                | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1  | 2       | 1\nVMOVAPS %ZMM17,%ZMM26                  | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 2       | 0.50\nXOR %ECX,%ECX\nVBROADCASTSS 0xc0(%RSP),%ZMM7{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xc4(%RSP),%ZMM6{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xc8(%RSP),%ZMM5{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xcc(%RSP),%ZMM2{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xd0(%RSP),%ZMM1{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS 0xd4(%RSP),%ZMM0{%K1}{z}  | 1     | 0.50 | 0.50 | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVBROADCASTSS %XMM18,%ZMM25             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM15,%ZMM24             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM14,%ZMM23             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM13,%ZMM22             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM21,%ZMM18             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVBROADCASTSS %XMM20,%ZMM9              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVPBROADCASTQ %R8,%ZMM11                | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3       | 1\nLEA (%R13,%R11,4),%R9                  | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nLEA (%RDX,%R11,4),%R10                 | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nLEA (%R12,%R11,4),%R11                 | 1     | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0  | 1       | 0.50\nVMOVUPS 0xf808(%RIP),%ZMM10            | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVMOVUPS 0xf77e(%RIP),%ZMM12            | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0  | 5       | 0.50\nVEXTRACTF64X4 $0x1,%ZMM1,%YMM15        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM1,%YMM15,%YMM1              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVEXTRACTF64X4 $0x1,%ZMM0,%YMM4         | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM0,%YMM4,%YMM8               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x56,%YMM1,%YMM0             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x1,%YMM8,%YMM3              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM8,%YMM9             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM8,%YMM10             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM8,%YMM3,%YMM11              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM12             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM1,%YMM3              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM12,%YMM11,%YMM13            | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $0x55,%YMM1,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM1,%YMM3,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM13,%XMM14             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM13,%XMM14,%XMM4             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVEXTRACTF64X4 $0x1,%ZMM2,%YMM13        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM8,%YMM0,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM2,%YMM13,%YMM1              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM1,%YMM2              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM1,%YMM0             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM1,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVEXTRACTF64X4 $0x1,%ZMM5,%YMM14        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM1,%YMM2,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM0,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM5,%YMM14,%YMM0              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM3             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM0,%YMM1              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM0,%YMM5             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM0,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVEXTRACTF64X4 $0x1,%ZMM6,%YMM13        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM0,%YMM1,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM5,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM6,%YMM13,%YMM5              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM2             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM5,%YMM0              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM5,%YMM6             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM5,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVEXTRACTF64X4 $0x1,%ZMM7,%YMM13        | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 3-6     | 1\nVADDPS %YMM5,%YMM0,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM6,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM7,%YMM13,%YMM6              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM1             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPERMPD $-0x1,%YMM6,%YMM5              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $-0x56,%YMM6,%YMM7             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVPERMPD $0x55,%YMM6,%YMM8              | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDPS %YMM6,%YMM5,%YMM9               | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM8,%YMM7,%YMM10              | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM0             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVADDPS %YMM10,%YMM9,%YMM11             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nVPSRLQ $0x20,%XMM11,%XMM12             | 1     | 1    | 0    | 0    | 0    | 0    | 0    | 0  | 2       | 1\nVADDSS %XMM11,%XMM12,%XMM5             | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0  | 6       | 0.50\nXOR %R11D,%R11D\nJMP 4047e7 <main+0x24f7>               | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 2\nMOV 0x40(%RSP),%R11                    | 1     | 0    | 0    | 1    | 0    | 0    | 0    | 0  | 4       | 1\nXOR %R8D,%R8D\nJMP 404423 <main+0x2133>               | 1     | 0    | 0    | 0    | 0    | 0    | 1    | 0  | 0       | 2\n",
        },
      },
      header = {
        "5% of peak computational performance is used (3.36 out of 64.00 FLOP per cycle (GFLOPS @ 1GHz))",
      },
      brief = {
      },
      gain = {
        {
          workaround = " - Try to reorganize arrays of structures to structures of arrays\n - Consider to permute loops (see vectorization gain report)\n",
          title = "Code clean check",
          txt = "Detected a slowdown caused by scalar integer instructions (typically used for address computation).\nBy removing them, you can lower the cost of an iteration from 59.00 to 51.00 cycles (1.16x speedup).",
        },
        {
          workaround = " - Try another compiler or update/tune your current one\n - Remove inter-iterations dependences from your loop and make it unit-stride:\n  * If your arrays have 2 or more dimensions, check whether elements are accessed contiguously and, otherwise, try to permute loops accordingly\n  * If your loop streams arrays of structures (AoS), try to use structures of arrays instead (SoA)\n",
          details = "58% of SSE/AVX instructions are used in vector version (process two or more data elements in vector registers):\n - 14% of SSE/AVX loads are used in vector version.\n - 0% of SSE/AVX stores are used in vector version.\n - 80% of SSE/AVX addition or subtraction instructions are used in vector version.\n - 57% of SSE/AVX instructions that are not load, store, addition, subtraction nor multiply instructions are used in vector version.\nSince your execution units are vector units, only a fully vectorized loop can use their full power.\n",
          title = "Vectorization",
          txt = "Your loop is partially vectorized.\nOnly 32% of vector register length is used (average across all SSE/AVX instructions).\nBy fully vectorizing your loop, you can lower the cost of an iteration from 59.00 to 26.56 cycles (2.22x speedup).",
        },
        {
          title = "Execution units bottlenecks",
          txt = "Found no such bottlenecks but see expert reports for more complex bottlenecks.",
        },
      },
      potential = {
      },
    },
  common = {
    header = {
      "",
      "Warnings:\n - Non-innermost loop: analyzing only self part (ignoring child loops).\n - Ignoring paths for analysis\n - Failed to get the number of paths\n - RecMII not computed since number of paths is unknown or > max_paths\n - Streams not analyzed since number of paths is unknown or > max_paths\n",
    },
  },
}
